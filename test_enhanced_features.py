#!/usr/bin/env python3
"""
å¢å¼ºåŠŸèƒ½æµ‹è¯•è„šæœ¬
éªŒè¯æ–°å¢åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import logging
from pathlib import Path
import yaml

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def test_config_loading():
    """æµ‹è¯•é…ç½®åŠ è½½åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•é…ç½®åŠ è½½...")
    
    try:
        from src.r1.configs import load_config
        
        # æµ‹è¯•å¢å¼ºç‰ˆé…ç½®
        config_path = "recipes/Qwen2.5-1.5B-Instruct/grpo/config_enhanced_demo.yaml"
        config = load_config(config_path)
        
        print(f"âœ“ é…ç½®åŠ è½½æˆåŠŸ")
        print(f"  æ¨¡å‹: {config.model_name_or_path}")
        print(f"  æ•°æ®é›†: {config.dataset_name}")
        
        # æ£€æŸ¥æ–°åŠŸèƒ½é…ç½®
        if hasattr(config, 'eval_steps'):
            print(f"  å®æ—¶è¯„ä¼°: æ¯{config.eval_steps}æ­¥")
        if hasattr(config, 'use_reject_sampling'):
            print(f"  æ‹’ç»é‡‡æ ·: {'å¯ç”¨' if config.use_reject_sampling else 'ç¦ç”¨'}")
        if hasattr(config, 'reward_weights'):
            print(f"  å¥–åŠ±æƒé‡: {config.reward_weights}")
            
        return True
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        return False

def test_reward_functions():
    """æµ‹è¯•å¥–åŠ±å‡½æ•°åˆ›å»º"""
    print("\nğŸ§ª æµ‹è¯•å¥–åŠ±å‡½æ•°...")
    
    try:
        from src.r1.rewards import create_reward_functions
        
        reward_names = ['accuracy', 'format', 'reasoning_steps', 'tag_count']
        reward_funcs = create_reward_functions(reward_names)
        
        print(f"âœ“ åˆ›å»ºäº†{len(reward_funcs)}ä¸ªå¥–åŠ±å‡½æ•°")
        for name, func in zip(reward_names, reward_funcs):
            print(f"  â€¢ {name}: {func.__name__}")
            
        return True
    except Exception as e:
        print(f"âŒ å¥–åŠ±å‡½æ•°åˆ›å»ºå¤±è´¥: {e}")
        return False

def test_yaml_config():
    """æµ‹è¯•YAMLé…ç½®æ–‡ä»¶æ ¼å¼"""
    print("\nğŸ§ª æµ‹è¯•YAMLé…ç½®æ ¼å¼...")
    
    try:
        config_path = "recipes/Qwen2.5-1.5B-Instruct/grpo/config_enhanced_demo.yaml"
        
        with open(config_path, 'r', encoding='utf-8') as f:
            yaml_data = yaml.safe_load(f)
            
        print("âœ“ YAMLé…ç½®æ ¼å¼æ­£ç¡®")
        
        # æ£€æŸ¥å…³é”®é…ç½®é¡¹
        required_keys = [
            'model_name_or_path', 'dataset_name', 'reward_funcs',
            'learning_rate', 'num_train_epochs'
        ]
        
        for key in required_keys:
            if key in yaml_data:
                print(f"  â€¢ {key}: âœ“")
            else:
                print(f"  â€¢ {key}: âŒ ç¼ºå¤±")
                
        # æ£€æŸ¥æ–°åŠŸèƒ½é…ç½®
        new_features = [
            'eval_steps', 'use_reject_sampling', 'reward_weights',
            'torch_empty_cache_steps', 'log_completion_details'
        ]
        
        print("  æ–°åŠŸèƒ½é…ç½®:")
        for key in new_features:
            if key in yaml_data:
                print(f"    â€¢ {key}: {yaml_data[key]}")
            else:
                print(f"    â€¢ {key}: æœªé…ç½®")
                
        return True
    except Exception as e:
        print(f"âŒ YAMLé…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_imports():
    """Test module imports"""
    print("\nğŸ§ª Testing module imports...")
    
    modules_to_test = [
        'src.r1.configs',
        'src.r1.trainer',
        'src.r1.rewards',
        'src.r1.callbacks',
        'src.r1.utils.logging',
        'src.r1.utils.formatting',
        'src.r1.utils.data'
    ]
    
    success = True
    for module in modules_to_test:
        try:
            __import__(module)
            print(f"  âœ“ {module}")
        except ImportError as e:
            print(f"  âŒ {module}: {e}")
            success = False
        except Exception as e:
            print(f"  âš ï¸ {module}: {e}")
            
    return success

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å¢å¼ºåŠŸèƒ½æµ‹è¯•\n")
    
    tests = [
        ("æ¨¡å—å¯¼å…¥", test_imports),
        ("YAMLé…ç½®", test_yaml_config),
        ("é…ç½®åŠ è½½", test_config_loading),
        ("å¥–åŠ±å‡½æ•°", test_reward_functions),
    ]
    
    results = []
    for test_name, test_func in tests:
        print(f"{'='*50}")
        print(f"æµ‹è¯•: {test_name}")
        result = test_func()
        results.append((test_name, result))
        
    print(f"\n{'='*50}")
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
    
    all_passed = True
    for test_name, result in results:
        status = "âœ“ é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {test_name}: {status}")
        if not result:
            all_passed = False
            
    print(f"\nğŸ¯ æ€»ä½“ç»“æœ: {'ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!' if all_passed else 'âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥'}")
    
    return 0 if all_passed else 1

if __name__ == "__main__":
    exit(main()) 